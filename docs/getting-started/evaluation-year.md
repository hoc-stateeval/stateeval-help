---
sidebar_position: 4
title: The Evaluation Year
---

# The Evaluation Year

An evaluation in eVAL spans the school year. This page outlines what happens when and how the pieces fit together.

## The Big Picture

Throughout the year, evidence is collected through different activities — observations, artifacts, student growth goals, and more. Each activity creates evidence that is aligned to your district's evaluation framework. At the end of the year, the evaluator reviews all the aggregated evidence and assigns a final summative score.

## Year at a Glance

| When | What Happens | Who's Involved |
|------|-------------|----------------|
| **Before school starts** | Administrators select frameworks, configure settings, assign evaluators and plan types | District Admin, School Admin |
| **Early fall** | Self-assessments, student growth goal setting | Evaluatee, Evaluator |
| **Throughout the year** | Observations, artifacts, coded notes | Evaluator, Evaluatee |
| **Mid-year** (optional) | Mid-year review checkpoint | Evaluator, Evaluatee |
| **Spring** | Final observations, summative reflections | Evaluator, Evaluatee |
| **End of year** | Summative scoring, final report, end-of-year conference | Evaluator |

## How Evidence Flows

Evidence starts in individual activities and flows into aggregated views:

1. **Created in activities** — Evidence is produced within observations, artifacts, student growth, coded notes, and self-assessments. While being worked on, evidence is typically private to the activity.

2. **Published** — When an activity is shared or locked (e.g., an observation is submitted), its evidence becomes visible beyond that activity.

3. **Aggregated in YTD Evidence** — The Year-to-Date Evidence view collects all published evidence across the full evaluation rubric, giving both parties a running view of everything gathered so far.

4. **Scored in Summative** — At year end, the Summative Evaluation aggregates evidence scoped to the evaluatee's plan type. The evaluator reviews this evidence and assigns scores for criteria C1-C8 and the student growth components, producing a final performance rating.

:::info YTD vs. Summative
**YTD Evidence** shows everything across the entire rubric, regardless of plan type. **Summative Evidence** shows only what's in scope for the evaluation plan type (all criteria for Comprehensive, or the selected focus criteria for Focused).
:::

## Plan Types

Each evaluatee is assigned either a **Comprehensive** or **Focused** plan type for the year:

- **Comprehensive** — All eight state criteria are evaluated and scored
- **Focused** — One selected criterion is the focus, along with student growth. Scores from the prior Comprehensive evaluation carry forward for the other criteria.

Your plan type affects which rubric components are in scope for evidence collection activities and what appears in the Summative evaluation. See [Focused Evaluations](../reference/focused-evaluations.md) for details on eligibility, configuration, and how scoring works.

## Evidence Collecting Activities

| Activity | What It Is | Created By |
|----------|-----------|------------|
| **Observations** | Formal classroom or leadership observations with pre/post-conference prompts; prompt responses can be included as evidence | Evaluator (evaluatee participates in conferences) |
| **Artifacts** | Documents, links, and narrative text as evidence of practice | Both parties |
| **Student Growth** | Goals set early in the year, achievement documented at year end | Evaluatee (approved by Evaluator) |
| **Coded Notes** | Informal evaluator notes linked to rubric criteria (walkthroughs, conversations) | Evaluator |
| **Self-Assessment** | Evaluatee self-reflection, typically at beginning of year | Evaluatee |

:::tip Observations
Observations are typically the most important evidence gathering activity for teacher evaluations. The number of required observations is determined by your district's contract, not by eVAL — the system supports as many observations as needed.
:::

:::note Self-Assessment Evidence
Evidence from self-assessments is for reflection purposes and is **not** included in the Summative evaluation.
:::

## Summative Scoring

At the end of the year, the evaluator completes the summative evaluation:

1. **Review aggregated evidence** aligned to each criterion
2. **Score C1-C8** — assign a performance level (1-4) for each state criterion
3. **Score student growth components** — these determine the Student Growth Impact Rating (Low, Average, or High)
4. **Final score** — automatically calculated from the criteria scores and student growth impact

The result is one of four performance levels: **Unsatisfactory**, **Basic**, **Proficient**, or **Distinguished**.

:::warning Student Growth Impact
A Low student growth impact rating will downgrade a Distinguished criteria score to Proficient. A score of 1 on any student growth component automatically results in a Low impact rating.
:::

## Related Topics

- [Understanding Your Evaluation](../reference/evaluation-basics.md) — Plan types, performance levels, the eight criteria
- [State Evaluation Framework](../reference/state-framework.md) — Frameworks, criteria details, student growth
- [Work Areas](./work-areas.md) — How to navigate eVAL based on your role
